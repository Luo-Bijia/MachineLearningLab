{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dba5c058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入所需库文件\n",
    "from numpy import *\n",
    "from functools import reduce\n",
    "import re\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7d150691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据集,加载数据\n",
    "adClass = 1  # 广告,垃圾标识\n",
    "\n",
    "def loadDataSet():\n",
    "    '''加载数据集合及其对应的分类'''\n",
    "    classVec = []    #0-1列表 第i个元素标识了wordList第i行类别\n",
    "    wordList = []    #提取出的词矩阵，每一行是对应一个邮件的单词列表\n",
    "    \n",
    "    smss = open(\"./SMSSpamCollection.txt\", 'r', encoding = 'utf-8')\n",
    "    data = csv.reader(smss, delimiter = '\\t')\n",
    "    for line in data:      #line:左边一个\"ham\" or \"spam\"，右边一个大字符串\n",
    "        if line[0] == \"ham\":\n",
    "            classVec.append(0)\n",
    "        else:\n",
    "            classVec.append(1)\n",
    "        wordList.append(textParse(line[1]))\n",
    "\n",
    "    return wordList, classVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "946bbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textParse(bigString):\n",
    "    '''接收一个长字符串解析成字符串列表'''\n",
    "    #将特殊符号作为划分标志进行字符串切分，即非字母，非数字\n",
    "    listOfTokens = re.split(r'\\W+', bigString)\n",
    "    #除单字母  其它单词全变成小写\n",
    "    return [tok.lower() for tok in listOfTokens if len(tok) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8f70513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2VecList(docList):\n",
    "    \"\"\"函数说明:数据进行并集操作，最后返回一个词不重复的并集\"\"\"\n",
    "    #reduce(function, iterable[, initializer]): 从左至右积累地应用到 iterable 的条目，以便将该可迭代对象缩减为单一的值\n",
    "    a = list(reduce(lambda x, y:set(x) | set(y), docList))\n",
    "    return a  #['','',...,'']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c673b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2Vec(vecList, inputWords):     #所有词，输入的词组\n",
    "    '''把单词转化为词向量'''\n",
    "    dimensions = len(vecList)\n",
    "    resultVec = [0] * dimensions\n",
    "    for i in range(dimensions):\n",
    "        if vecList[i] in inputWords:\n",
    "            resultVec[i] += 1\n",
    "    #转化为一维数组\n",
    "    return array(resultVec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3ff3fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNB(trainMatrix, trainClass):\n",
    "    \"\"\"函数说明:计算，生成每个词对于类别上的概率\"\"\"\n",
    "    # 类别行数\n",
    "    numTrainClass = len(trainClass)\n",
    "    # 列数\n",
    "    numWords = len(trainMatrix[0])\n",
    "\n",
    "    '''Laplacian +1平滑'''\n",
    "    # 全部都初始化为1(全1数组)， 防止出现概率为0的情况\n",
    "    p0Num = ones(numWords)\n",
    "    p1Num = ones(numWords)\n",
    "    # 相应的单词初始化为2\n",
    "    p0Words = 2.0\n",
    "    p1Words = 2.0\n",
    "\n",
    "    # 统计每个分类的词的总数\n",
    "    for i in range(numTrainClass):\n",
    "        if trainClass[i] == 1:\n",
    "            # 数组在对应的位置上相加\n",
    "            p1Num += trainMatrix[i]\n",
    "            p1Words += sum(trainMatrix[i])\n",
    "        else:\n",
    "            p0Num += trainMatrix[i]\n",
    "            p0Words += sum(trainMatrix[i])\n",
    "\n",
    "    # 计算每种类型里面， 每个单词出现的概率\n",
    "    # 在计算过程中，由于概率的值较小，于是取对数扩大数值域\n",
    "    p0Vec = log(p0Num / p0Words)\n",
    "    p1Vec = log(p1Num / p1Words)\n",
    "\n",
    "    # 计算在类别中1出现的概率，0出现的概率可通过1-p得到\n",
    "    pClass1 = sum(trainClass) / float(numTrainClass)\n",
    "    return p0Vec, p1Vec, pClass1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "33e9ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyNB(testVec, p0Vec, p1Vec, pClass1):\n",
    "    \"\"\"分类, 返回分类结果 0 or 1\"\"\"\n",
    "    # 因为概率的值太小了，所以乘法改加法\n",
    "    # 根据对数特性ln{ P(c)×P(X1|c)×P(X2|c)×...×P(Xn|c) } = lnP(c) + lnP(X1|c) + ... + lnP(Xn|c)\n",
    "    # 可以简化计算且不失精度\n",
    "    '''test * pVec已经在trainNB中取过对数了直接相加'''\n",
    "    p1 = sum(testVec * p1Vec) + log(pClass1)\n",
    "    p0 = sum(testVec * p0Vec) + log(1 - pClass1)\n",
    "    if p0 > p1:\n",
    "        return 0\n",
    "    return 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e1e5ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printClass(words, testClass):\n",
    "    if testClass == adClass:\n",
    "        print(words, '推测为：广告邮件')\n",
    "    else:\n",
    "        print(words, '推测为：正常邮件')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "53771d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tNB():\n",
    "    # 加载训练数据集\n",
    "    docList, classVec = loadDataSet()    #单词矩阵、 01向量\n",
    "    \n",
    "    # 生成包含所有单词的list\n",
    "    allWordsVec = doc2VecList(docList)\n",
    "    \n",
    "    # 构建词向量矩阵\n",
    "    '''lambda中的x对应docList的每一行词组'''\n",
    "    trainMat = list(map(lambda x : words2Vec(allWordsVec, x), docList))   #和docList对应的行(词)向量组\n",
    "    \n",
    "    # 训练计算每个词在分类上的概率\n",
    "    # 其中p0V:每个单词在“非”分类出现的概率， p1V:每个单词在“是”分类出现的概率  pClass1：类别中是1的概率\n",
    "    p0V, p1V, pClass1 = trainNB(trainMat, classVec)\n",
    "    \n",
    "    # 测试数据集\n",
    "    text1 = \"As a valued cutomer, I am pleased to advise you that following recent review of your Mob No\"\n",
    "    testwords1 = textParse(text1)\n",
    "    testVec1 = words2Vec(allWordsVec, testwords1)\n",
    "    # 通过将单词向量testVec代入，根据贝叶斯公式，比较各个类别的后验概率，判断当前数据的分类情况\n",
    "    testClass1 = classifyNB(testVec1, p0V, p1V, pClass1)\n",
    "    # 打印出测试结果\n",
    "    printClass(testwords1, testClass1)\n",
    "    \n",
    "    text2 = \"Please don't text me anymore. I have nothing else to say\"\n",
    "    testwords2 = textParse(text2)\n",
    "    testVec2 = words2Vec(allWordsVec, testwords2)\n",
    "    testClass2 = classifyNB(testVec2, p0V, p1V, pClass1)\n",
    "    printClass(testwords2, testClass2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a6aad582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['valued', 'cutomer', 'pleased', 'advise', 'you', 'that', 'following', 'recent', 'review', 'your', 'mob'] 推测为：广告邮件\n",
      "['please', 'don', 'text', 'anymore', 'have', 'nothing', 'else', 'say'] 推测为：正常邮件\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6152b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
