{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dba5c058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入所需库文件\n",
    "from numpy import *\n",
    "from functools import reduce\n",
    "import re\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7d150691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据集,加载数据\n",
    "adClass = 1  # 广告,垃圾标识\n",
    "\n",
    "def loadDataSet():\n",
    "    '''加载数据集合及其对应的分类'''\n",
    "    wordList = [['周六', '公司', '一起', '聚餐', '时间'],\n",
    "                ['优惠', '返利', '打折', '优惠', '金融', '理财'],\n",
    "    ['喜欢', '机器学习', '一起', '研究', '欢迎', '贝叶斯', '算法', '公式'],\n",
    "    ['公司', '发票', '税点', '优惠', '增值税', '打折'],\n",
    "    ['北京', '今天', '雾霾', '不宜', '外出', '时间', '在家', '讨论', '学习'],\n",
    "    ['招聘', '兼职', '日薪', '保险', '返利']]\n",
    "\n",
    "    # 1：广告  0：正常\n",
    "    classVec = [0, 1, 0, 1, 0, 1]\n",
    "    return wordList, classVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8f70513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2VecList(docList):\n",
    "    \"\"\"函数说明:数据进行并集操作，最后返回一个词不重复的并集\"\"\"\n",
    "    #reduce(function, iterable[, initializer]): 从左至右积累地应用到 iterable 的条目，以便将该可迭代对象缩减为单一的值\n",
    "    a = list(reduce(lambda x, y:set(x) | set(y), docList))\n",
    "    return a  #['','',...,'']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c673b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2Vec(vecList, inputWords):     #所有词，输入的词组\n",
    "    '''把单词转化为词向量'''\n",
    "    dimensions = len(vecList)\n",
    "    resultVec = [0] * dimensions\n",
    "    for i in range(dimensions):\n",
    "        if vecList[i] in inputWords:\n",
    "            resultVec[i] += 1\n",
    "    #转化为一维数组\n",
    "    return array(resultVec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3ff3fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNB(trainMatrix, trainClass):\n",
    "    \"\"\"函数说明:计算，生成每个词对于类别上的概率\"\"\"\n",
    "    # 类别行数——6\n",
    "    numTrainClass = len(trainClass)\n",
    "    # 列数——32\n",
    "    numWords = len(trainMatrix[0])\n",
    "\n",
    "    '''Laplacian +1平滑'''\n",
    "    # 全部都初始化为1(全1数组)， 防止出现概率为0的情况\n",
    "    p0Num = ones(numWords)\n",
    "    p1Num = ones(numWords)\n",
    "    # 相应的单词初始化为2\n",
    "    p0Words = 2.0\n",
    "    p1Words = 2.0\n",
    "\n",
    "    # 统计每个分类的词的总数\n",
    "    for i in range(numTrainClass):\n",
    "        if trainClass[i] == 1:\n",
    "            # 数组在对应的位置上相加\n",
    "            p1Num += trainMatrix[i]\n",
    "            p1Words += sum(trainMatrix[i])\n",
    "        else:\n",
    "            p0Num += trainMatrix[i]\n",
    "            p0Words += sum(trainMatrix[i])\n",
    "\n",
    "    # 计算每种类型里面， 每个单词出现的概率\n",
    "    # 在计算过程中，由于概率的值较小，于是取对数扩大数值域\n",
    "    p0Vec = log(p0Num / p0Words)\n",
    "    p1Vec = log(p1Num / p1Words)\n",
    "\n",
    "    # 计算在类别中1出现的概率，0出现的概率可通过1-p得到\n",
    "    pClass1 = sum(trainClass) / float(numTrainClass)\n",
    "    return p0Vec, p1Vec, pClass1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "33e9ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyNB(testVec, p0Vec, p1Vec, pClass1):\n",
    "    \"\"\"分类, 返回分类结果 0 or 1\"\"\"\n",
    "    # 因为概率的值太小了，所以乘法改加法\n",
    "    # 根据对数特性ln{ P(c)×P(X1|c)×P(X2|c)×...×P(Xn|c) } = lnP(c) + lnP(X1|c) + ... + lnP(Xn|c)\n",
    "    # 可以简化计算且不失精度\n",
    "    '''test * pVec已经在trainNB中取过对数了直接相加'''\n",
    "    p1 = sum(testVec * p1Vec) + log(pClass1)\n",
    "    p0 = sum(testVec * p0Vec) + log(1 - pClass1)\n",
    "    if p0 > p1:\n",
    "        return 0\n",
    "    return 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e1e5ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printClass(words, testClass):\n",
    "    if testClass == adClass:\n",
    "        print(words, '推测为：广告邮件')\n",
    "    else:\n",
    "        print(words, '推测为：正常邮件')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "53771d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tNB():\n",
    "    # 加载训练数据集\n",
    "    docList, classVec = loadDataSet()    #单词矩阵、 01向量\n",
    "    \n",
    "    # 生成包含所有单词的list\n",
    "    allWordsVec = doc2VecList(docList)\n",
    "    \n",
    "    # 构建词向量矩阵\n",
    "    '''lambda中的x对应docList的每一行词组'''\n",
    "    trainMat = list(map(lambda x : words2Vec(allWordsVec, x), docList))   #和docList对应的行(词)向量组\n",
    "    \n",
    "    # 训练计算每个词在分类上的概率\n",
    "    # 其中p0V:每个单词在“非”分类出现的概率， p1V:每个单词在“是”分类出现的概率  pClass1：类别中是1的概率\n",
    "    p0V, p1V, pClass1 = trainNB(trainMat, classVec)\n",
    "    \n",
    "    # 测试数据集\n",
    "    testwords = ['公司', '聚餐', '讨论', '贝叶斯']\n",
    "    \n",
    "    # 转换成单词向量，32个单词构成的数组，如果此单词在数组中，数组的项值置1\n",
    "    testVec = words2Vec(allWordsVec, testwords)\n",
    "    \n",
    "    # 通过将单词向量testVec代入，根据贝叶斯公式，比较各个类别的后验概率，判断当前数据的分类情况\n",
    "    testClass = classifyNB(testVec, p0V, p1V, pClass1)\n",
    "    \n",
    "    # 打印出测试结果\n",
    "    printClass(testwords, testClass)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a6aad582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['公司', '聚餐', '讨论', '贝叶斯'] 推测为：正常邮件\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6152b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
